# Overview

**Legend:**

* ✅ **Verified** — Factual claims confirmed directly from the source material  
  - 10 in this category  
* 🟠 **Partially True** — Claims that are not strictly correct but are "truthy" (e.g. exaggerated, over-interpreted, from the wrong source)  
  - 5 in this category  
* ⚪ **Unverifiable** — Claims that could not be verified or debunked (e.g. no source given)  
  - 1 in this category  
* ❌ **False** — Outright incorrect claims  
  - 1 in this category  

> What counts as a discrete claim is a bit subjective in this case since some 'claims' are multipart (e.g., "the people think X, Y, Z", "people are more X in 2025 than in 2015"). In general, I'm treating a single statement as a discrete claim.

# Sample of Claims

## Claim: Concern about AI outweighs excitement — and is growing over time

* **Scope:** U.S. (Pew Research Center, YouGov, Gallup), UK (Gov.uk, Turing Institute)  
* **Timing:** 2018–2025  

✅ **In Pew’s 2023 nationally representative survey, 52% of Americans said they felt more *concerned* than *excited*** about AI’s growing role in daily life, up significantly from 2021.  
✅ [YouGov (March 2025)](https://today.yougov.com/technology/articles/51803-americans-increasingly-skeptical-about-ai-artificial-intelligence-effects-poll) also found that terms like “concerned,” “cautious,” and “skeptical” were dominant, and had increased from prior waves (44% described themselves as skeptical, up from 36% in 2024).  
* This growing concern is especially pronounced around misinformation, job loss, surveillance, and loss of control.

> ✅ **Derived from quantitative data** (% concerned; tracked over time)  
> ⚠️ Trend direction is consistent across U.S. and UK, though British surveys show slightly more domain-specific nuance (e.g., high concern for autonomous weapons, but support for AI in health).

---

## Claim: Public trust in AI varies sharply by *use case*, not just by exposure or knowledge

* **Scope:** U.S., UK, Germany  
* **Timing:** 2018–2025  

🟠 Across multiple studies ([Pew 2025](https://www.pewresearch.org/wp-content/uploads/sites/20/2025/04/pi_2025.04.03_us-public-and-ai-experts_report.pdf), [Ada/Turing 2023](https://www.turing.ac.uk/sites/default/files/2023-06/how_do_people_feel_about_ai_-_ada_turing.pdf), [Scientific Reports 2024](https://www.nature.com/articles/s41598-024-53335-2)), people were much more supportive of AI in health (e.g., cancer detection, diagnostics) than in hiring, autonomous vehicles, or political applications.  
🟠 @SB: In the Pew report, there wasn't a ton of evidence that people were especially positive towards health other than a quote from experts  
❌ @SB: Nothing about this in the Scientific Reports paper  
🟠 @SB: Support for healthcare applications in the Ada/Turing report, but no comparison to other applications  

✅ Ada/Turing (UK, 2023) found 90% support for AI in cancer detection, but over 70% concern for driverless cars and autonomous weapons.  
⚪ Pew and Gallup also found low support for AI in employment decision-making (e.g., 71% of Americans oppose AI making final hiring decisions @SB: could not find source for this claim).

---

## Claim: Institutional trust mediates public acceptance of AI

* **Scope:** U.S., UK  
* **Timing:** 2018–2025  

✅ Respondents consistently trust academic institutions and healthcare providers more than tech companies or government to manage or deploy AI.  
✅ In both the UK Government tracker (2024) and  
🟠 NAIOM (USA, 2024–2025) (@SB: no comparison made to NHS here), the NHS and university researchers received the highest trust, while social media companies, Facebook, and federal government ranked lowest.  
✅ In the [Edelman 2019 survey](https://www.edelman.com/sites/g/files/aatuss191/files/2019-03/2019_Edelman_AI_Survey_Whitepaper.pdf), even tech executives shared the public’s concern about misuse of AI, especially around deepfakes and inequality.

---

## Claim: Concern about AI has increased faster than excitement

* **Change Over Time:**  

🟠 **Pew (2018):** AI was broadly seen as promising but unfamiliar — most respondents expressed neutral or cautious optimism (@SB: technically one of the Pew studies does say something along these lines, but there was no 2018 Pew study in the list of sources; though, a 2018 Pew study *does exist* that supports this claim).  
✅ **Pew (2023):** A clear shift occurred: 52% of Americans said they were more concerned than excited about AI’s growing role, up from 38% in 2022.  
✅ **YouGov (2025):** The share describing themselves as “skeptical” increased to 44%, up from 36% in 2024.  
❌ **Gallup & Telescope (2024):** Found 63% of Americans expressed concern about AI, with only 24% expressing optimism (@SB: this kind of question was not asked).

---

## Claim: Support for regulation and human oversight has strengthened

* **Change Over Time:**  

✅ **Edelman (2019):** 60% of Americans and 54% of tech executives supported stronger AI regulation.  
✅ **Turing Institute (2023):** 62% of UK adults wanted new laws to govern AI.  
✅ **Pew (2025):** Found growing public support for requiring “human explainability” and government oversight, especially in high-risk domains like hiring or elections.

---

## Claim: Most Polarizing Domain: Hiring and Workplace Automation

### Early studies (2018–2019):

* **Zhang & Dafoe (2019):** Public was divided on AI replacing human labor — many saw it as inevitable but dangerous.  
✅ Support for high-level machine intelligence was 31% in favor, 27% opposed.

### Recent studies (2022–2025):

✅ **Pew (2022):**  
* 71% oppose AI making final hiring decisions  
* Only 1 in 5 Americans said they trust companies to use AI fairly in evaluating workers  

🟠 **Pew (2025):** Perceived AI impact on workers is high (62%), but personal impact is low (28%), showing persistent disconnection (@SB: correct, but this is from Pew (2023), not 2025)

### 🔍 Confidence:

⚠️ **Moderate to high confidence in long-standing ambivalence**, though some findings (e.g., personal impact perceptions) are mixed and framing-sensitive.

---

## Claim: Perceived personal impact of AI remains low, despite growing use

* **Change Over Time:**  

✅ **Gallup & Northeastern (2017):** 73% expected AI would eliminate more jobs than it creates.  
🟠 **Pew (2025):** While 62% said AI would impact U.S. workers, only 28% believed it would affect them personally.  
* This gap between general concern and personal concern has widened, even as tools like ChatGPT become embedded in everyday work and communication.

* **Substantive Shift?** ⚠️ **Mixed — stable personal detachment despite rising usage**  
* **Statistical Confidence?** ⚠️ Moderate — longitudinal questions about personal impact are less common, and trends depend on framing
