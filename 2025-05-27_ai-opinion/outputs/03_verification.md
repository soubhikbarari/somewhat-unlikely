# Overview

**Legend:**

* âœ… **Verified** â€” Factual claims confirmed directly from the source material  
  - 10 in this category  
* ğŸŸ  **Partially True** â€” Claims that are not strictly correct but are "truthy" (e.g. exaggerated, over-interpreted, from the wrong source)  
  - 5 in this category  
* âšª **Unverifiable** â€” Claims that could not be verified or debunked (e.g. no source given)  
  - 1 in this category  
* âŒ **False** â€” Outright incorrect claims  
  - 1 in this category  

> What counts as a discrete claim is a bit subjective in this case since some 'claims' are multipart (e.g., "the people think X, Y, Z", "people are more X in 2025 than in 2015"). In general, I'm treating a single statement as a discrete claim.

# Sample of Claims

## Claim: Concern about AI outweighs excitement â€” and is growing over time

* **Scope:** U.S. (Pew Research Center, YouGov, Gallup), UK (Gov.uk, Turing Institute)  
* **Timing:** 2018â€“2025  

âœ… **In Pewâ€™s 2023 nationally representative survey, 52% of Americans said they felt more *concerned* than *excited*** about AIâ€™s growing role in daily life, up significantly from 2021.  
âœ… [YouGov (March 2025)](https://today.yougov.com/technology/articles/51803-americans-increasingly-skeptical-about-ai-artificial-intelligence-effects-poll) also found that terms like â€œconcerned,â€ â€œcautious,â€ and â€œskepticalâ€ were dominant, and had increased from prior waves (44% described themselves as skeptical, up from 36% in 2024).  
* This growing concern is especially pronounced around misinformation, job loss, surveillance, and loss of control.

> âœ… **Derived from quantitative data** (% concerned; tracked over time)  
> âš ï¸ Trend direction is consistent across U.S. and UK, though British surveys show slightly more domain-specific nuance (e.g., high concern for autonomous weapons, but support for AI in health).

---

## Claim: Public trust in AI varies sharply by *use case*, not just by exposure or knowledge

* **Scope:** U.S., UK, Germany  
* **Timing:** 2018â€“2025  

ğŸŸ  Across multiple studies ([Pew 2025](https://www.pewresearch.org/wp-content/uploads/sites/20/2025/04/pi_2025.04.03_us-public-and-ai-experts_report.pdf), [Ada/Turing 2023](https://www.turing.ac.uk/sites/default/files/2023-06/how_do_people_feel_about_ai_-_ada_turing.pdf), [Scientific Reports 2024](https://www.nature.com/articles/s41598-024-53335-2)), people were much more supportive of AI in health (e.g., cancer detection, diagnostics) than in hiring, autonomous vehicles, or political applications.  
ğŸŸ  @SB: In the Pew report, there wasn't a ton of evidence that people were especially positive towards health other than a quote from experts  
âŒ @SB: Nothing about this in the Scientific Reports paper  
ğŸŸ  @SB: Support for healthcare applications in the Ada/Turing report, but no comparison to other applications  

âœ… Ada/Turing (UK, 2023) found 90% support for AI in cancer detection, but over 70% concern for driverless cars and autonomous weapons.  
âšª Pew and Gallup also found low support for AI in employment decision-making (e.g., 71% of Americans oppose AI making final hiring decisions @SB: could not find source for this claim).

---

## Claim: Institutional trust mediates public acceptance of AI

* **Scope:** U.S., UK  
* **Timing:** 2018â€“2025  

âœ… Respondents consistently trust academic institutions and healthcare providers more than tech companies or government to manage or deploy AI.  
âœ… In both the UK Government tracker (2024) and  
ğŸŸ  NAIOM (USA, 2024â€“2025) (@SB: no comparison made to NHS here), the NHS and university researchers received the highest trust, while social media companies, Facebook, and federal government ranked lowest.  
âœ… In the [Edelman 2019 survey](https://www.edelman.com/sites/g/files/aatuss191/files/2019-03/2019_Edelman_AI_Survey_Whitepaper.pdf), even tech executives shared the publicâ€™s concern about misuse of AI, especially around deepfakes and inequality.

---

## Claim: Concern about AI has increased faster than excitement

* **Change Over Time:**  

ğŸŸ  **Pew (2018):** AI was broadly seen as promising but unfamiliar â€” most respondents expressed neutral or cautious optimism (@SB: technically one of the Pew studies does say something along these lines, but there was no 2018 Pew study in the list of sources; though, a 2018 Pew study *does exist* that supports this claim).  
âœ… **Pew (2023):** A clear shift occurred: 52% of Americans said they were more concerned than excited about AIâ€™s growing role, up from 38% in 2022.  
âœ… **YouGov (2025):** The share describing themselves as â€œskepticalâ€ increased to 44%, up from 36% in 2024.  
âŒ **Gallup & Telescope (2024):** Found 63% of Americans expressed concern about AI, with only 24% expressing optimism (@SB: this kind of question was not asked).

---

## Claim: Support for regulation and human oversight has strengthened

* **Change Over Time:**  

âœ… **Edelman (2019):** 60% of Americans and 54% of tech executives supported stronger AI regulation.  
âœ… **Turing Institute (2023):** 62% of UK adults wanted new laws to govern AI.  
âœ… **Pew (2025):** Found growing public support for requiring â€œhuman explainabilityâ€ and government oversight, especially in high-risk domains like hiring or elections.

---

## Claim: Most Polarizing Domain: Hiring and Workplace Automation

### Early studies (2018â€“2019):

* **Zhang & Dafoe (2019):** Public was divided on AI replacing human labor â€” many saw it as inevitable but dangerous.  
âœ… Support for high-level machine intelligence was 31% in favor, 27% opposed.

### Recent studies (2022â€“2025):

âœ… **Pew (2022):**  
* 71% oppose AI making final hiring decisions  
* Only 1 in 5 Americans said they trust companies to use AI fairly in evaluating workers  

ğŸŸ  **Pew (2025):** Perceived AI impact on workers is high (62%), but personal impact is low (28%), showing persistent disconnection (@SB: correct, but this is from Pew (2023), not 2025)

### ğŸ” Confidence:

âš ï¸ **Moderate to high confidence in long-standing ambivalence**, though some findings (e.g., personal impact perceptions) are mixed and framing-sensitive.

---

## Claim: Perceived personal impact of AI remains low, despite growing use

* **Change Over Time:**  

âœ… **Gallup & Northeastern (2017):** 73% expected AI would eliminate more jobs than it creates.  
ğŸŸ  **Pew (2025):** While 62% said AI would impact U.S. workers, only 28% believed it would affect them personally.  
* This gap between general concern and personal concern has widened, even as tools like ChatGPT become embedded in everyday work and communication.

* **Substantive Shift?** âš ï¸ **Mixed â€” stable personal detachment despite rising usage**  
* **Statistical Confidence?** âš ï¸ Moderate â€” longitudinal questions about personal impact are less common, and trends depend on framing
