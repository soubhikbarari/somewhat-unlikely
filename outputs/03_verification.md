# Overview

Note: 
* <span style="color:green">Green text</span> demarcates factual claims that I've verified to be strictly correct from the source material.
  - 10 in this category
* <span style="color:orange">Orange text</span> demarcates factual claims that are not strictly correct, but 'truthy' (e.g. exaggerated, over-interpreted, wrong source)
  - 5 in this category
* <span style="color:grey">Grey text</span> demarcates factual claims that could not be verified or debunked (e.g. no source material given)
  - 1 in this category
* <span style="color:red">Red text</span> demarcates factual claims that are out-right false.
  - 1 in this category

What counts as a discrete claim is a bit subjective in this case since some 'claims' are multipart (e.g., "the people think X, Y, Z", "people are more X in 2025 than in 2015"). In general, I'm treating a single statement as a discrete claim.

# Sample of Claims

## Claim: Concern about AI outweighs excitement ‚Äî and is growing over time

* **Scope:** U.S. (Pew Research Center, YouGov, Gallup), UK (Gov.uk, Turing Institute)
* **Timing:** 2018‚Äì2025
* In [Pew‚Äôs 2023 nationally representative survey](https://www.pewresearch.org/short-reads/2023/11/21/what-the-data-says-about-americans-views-of-artificial-intelligence/), <span style="color:green">**52% of Americans said they felt more *concerned* than *excited*** about AI‚Äôs growing role in daily life, up significantly from 2021.</span>
* [YouGov (March 2025)](https://today.yougov.com/technology/articles/51803-americans-increasingly-skeptical-about-ai-artificial-intelligence-effects-poll) also found that **terms like ‚Äúconcerned,‚Äù ‚Äúcautious,‚Äù and ‚Äúskeptical‚Äù were dominant**, and had increased from prior waves <span style="color:green">(44% described themselves as skeptical, up from 36% in 2024)</span>.
* This growing concern is especially pronounced around misinformation, job loss, surveillance, and loss of control.

> ‚úÖ **Derived from quantitative data** (% concerned; tracked over time)
> ‚ö†Ô∏è Trend direction is consistent across U.S. and UK, though British surveys show slightly more domain-specific nuance (e.g., high concern for autonomous weapons, but support for AI in health).

---

## Claim: Public trust in AI varies sharply by *use case*, not just by exposure or knowledge

* **Scope:** U.S., UK, Germany
* **Timing:** 2018‚Äì2025
* Across multiple studies ([Pew 2025](https://www.pewresearch.org/wp-content/uploads/sites/20/2025/04/pi_2025.04.03_us-public-and-ai-experts_report.pdf), [Ada/Turing 2023]((https://www.turing.ac.uk/sites/default/files/2023-06/how_do_people_feel_about_ai_-_ada_turing.pdf)), [Scientific Reports 2024]((https://www.nature.com/articles/s41598-024-53335-2))), <span style="color:orange">people were **much more supportive of AI in health (e.g., cancer detection, diagnostics)** than in hiring, autonomous vehicles, or political applications</span>.
  - <span style="color:orange">@SB: In the Pew report, there wasn't a ton of evidence that people were especially positive towards health other than a quote from experts</span>
  -<span style="color:red">@SB: Nothing about this in the Scientific Reports paper</span>
  -<span style="color:orange">@SB: Support for healthcare applications in the Ada/Turing report, but no comparison to other applications</span>

* Ada/Turing (UK, 2023) <span style="color:green">found **90% support for AI in cancer detection**, but over **70% concern for driverless cars and autonomous weapons**</span>. Pew and Gallup also found low support for AI in employment decision-making (e.g., <span style="color:grey">71% of Americans oppose AI making final hiring decisions (@SB: could not find source for this claim)</span>).

> ‚úÖ **Derived from survey questions assessing attitudes by domain**
> üß† Suggests domain-specific trust is more predictive than general AI exposure

---

## Claim: Institutional trust mediates public acceptance of AI

* **Scope:** U.S., UK
* **Timing:** 2018‚Äì2025
* Respondents consistently **trust academic institutions and healthcare providers more than tech companies or government** to manage or deploy AI.
* In both the <span style="color:green">UK Government tracker (2024)</span> and <span style="color:orange">NAIOM (USA, 2024‚Äì2025) (@SB: no comparison made to NHS here)</span>, **the NHS and university researchers received the highest trust**, while **social media companies, Facebook, and federal government ranked lowest**.
* In the [Edelman 2019 survey](https://www.edelman.com/sites/g/files/aatuss191/files/2019-03/2019_Edelman_AI_Survey_Whitepaper.pdf), <span style="color:green">even tech executives shared the public‚Äôs concern about misuse of AI, especially around deepfakes and inequality</span>.

> ‚úÖ **Derived from trust batteries in surveys**
> üß† Suggests that trust in *who* uses AI is as important as trust in the technology itself

---

## Claim: Concern about AI has increased faster than excitement

* **Change Over Time:**

  * <span style="color:orange">**Pew (2018):** AI was broadly seen as promising but unfamiliar ‚Äî most respondents expressed **neutral or cautious optimism** (@SB: technically one of the Pew studies does say something along these lines, but there was no 2018 Pew study in the list of sources; though, a 2018 Pew study *does exist* that supports this claim)</span>.
  * **Pew (2023):** A clear shift occurred: <span style="color:green">**52% of Americans said they were more concerned than excited** about AI‚Äôs growing role, up from **38% in 2022**.</span>
  * **YouGov (2025):** <span style="color:green">The share describing themselves as **‚Äúskeptical‚Äù increased to 44%**, up from 36% in 2024.</span>
  * **Gallup & Telescope (2024):** <span style="color:red">Found **63% of Americans expressed concern** about AI, with **only 24% expressing optimism** (@SB: this kind of question was not asked)</span>.

* **Substantive Shift?** ‚úÖ **Yes ‚Äî large and consistent across sources**

* **Statistical Confidence?** ‚úÖ Strong: multiple nationally representative samples (Pew \~11,000; Gallup \~4,000)

---

## Claim: Support for regulation and human oversight has strengthened

* **Change Over Time:**

  * **Edelman (2019):** <span style="color:green">60% of Americans and 54% of tech executives supported stronger AI regulation</span>.
  * **Turing Institute (2023):** <span style="color:green">**62% of UK adults** wanted new laws to govern AI</span>.
  * **Pew (2025):** Found <span style="color:green">growing public support for requiring **‚Äúhuman explainability‚Äù and government oversight**, especially in high-risk domains like hiring or elections</span>.

* **Substantive Shift?** ‚úÖ **Yes ‚Äî sustained and cross-national**

* **Statistical Confidence?** ‚ö†Ô∏è Moderate to strong, though **regulatory support intensity varies** depending on question wording and application domain

---


## Claim: Most Polarizing Domain: Hiring and Workplace Automation

### Early studies (2018‚Äì2019):

* **Zhang & Dafoe (2019):** Public was **divided on AI replacing human labor** ‚Äî many saw it as **inevitable but dangerous**.

  * Support for <span style="color:green">**high-level machine intelligence** was **31% in favor, 27% opposed**</span>.

### Recent studies (2022‚Äì2025):

* **Pew (2022):**

  * <span style="color:green">**71% oppose AI making final hiring decisions**</span>.
  * Only **1 in 5 Americans** said they trust companies to use AI fairly in evaluating workers.
* **Pew (2025):** <span style="color:orange">Perceived AI impact on workers is **high (62%)**, but personal impact is **low (28%)**, showing persistent disconnection (@SB: correct, but this is from Pew (2023), not 2025)</span>.

### üîç Confidence:

‚ö†Ô∏è **Moderate to high confidence in long-standing ambivalence**, though some findings (e.g., personal impact perceptions) are mixed and framing-sensitive.

---

## Claim: Perceived personal impact of AI remains low, despite growing use

* **Change Over Time:**

  * **Gallup & Northeastern (2017):** <span style="color:green">73% expected AI would eliminate more jobs than it creates</span>.
  * **Pew (2025):** While *<span style="color:orange">*62% said AI would impact U.S. workers**, only **28% believed it would affect them personally**</span>.
  * This **gap between general concern and personal concern** has widened, even as tools like ChatGPT become embedded in everyday work and communication.

* **Substantive Shift?** ‚ö†Ô∏è **Mixed ‚Äî stable personal detachment despite rising usage**

* **Statistical Confidence?** ‚ö†Ô∏è Moderate ‚Äî longitudinal questions about personal impact are less common, and trends depend on framing
